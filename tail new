import streamlit as st
import pandas as pd
import numpy as np
import altair as alt
from st_aggrid import AgGrid, GridOptionsBuilder, JsCode
import re
from functools import reduce

# --- 1. Page Configuration & Initial Setup ---
st.set_page_config(
    page_title="Market Risk DVaR & SVaR Tail Analysis",
    page_icon="üìâ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- 2. Helper Functions (with Caching) ---

def extract_pnl_rank(col_name):
    """
    Extracts the numeric part of a pnl_vector column name using regex.
    Handles various naming conventions like 'pnl_vector261' or 'pnl_vector1[T-2]'.
    """
    if not isinstance(col_name, str):
        return None
    match = re.search(r'\d+', col_name)
    return int(match.group(0)) if match else None

@st.cache_data
def load_and_process_data(uploaded_file):
    """
    Loads data from the four specified sheets of the uploaded Excel file.
    It handles the two-row header structure, standardizes asset class names,
    cleans the data, and transforms it into a long format.

    Returns:
        A dictionary of processed pandas DataFrames and a boolean for success.
    """
    if uploaded_file is None:
        return None, False

    try:
        # Define the sheets to be processed and their associated metadata
        sheet_map = {
            "DVaR_COB": {"var_type": "DVaR", "sheet_type": "current"},
            "DVaR_Prev_COB": {"var_type": "DVaR", "sheet_type": "previous"},
            "SVaR_COB": {"var_type": "SVaR", "sheet_type": "current"},
            "SVaR_Prev_COB": {"var_type": "SVaR", "sheet_type": "previous"}
        }
        all_processed_dfs = {}

        for sheet_name, metadata in sheet_map.items():
            df_data = pd.read_excel(uploaded_file, sheet_name=sheet_name, header=1)
            df_dates = pd.read_excel(uploaded_file, sheet_name=sheet_name, header=None, nrows=1)
            
            pnl_headers = df_data.columns[6:].tolist()
            date_values = df_dates.iloc[0, 6:].tolist()
            date_mapping = {header: date for header, date in zip(pnl_headers, date_values)}

            desc_cols = df_data.columns[:6].tolist()
            df_long = pd.melt(df_data, id_vars=desc_cols, value_vars=pnl_headers, 
                              var_name='Pnl_Vector_Name', value_name='Value')

            df_long['Date'] = pd.to_datetime(df_long['Pnl_Vector_Name'].map(date_mapping))
            df_long['Pnl_Vector_Rank'] = df_long['Pnl_Vector_Name'].apply(extract_pnl_rank)
            df_long['Var_Type'] = metadata['var_type']
            df_long['Sheet_Type'] = metadata['sheet_type']
            
            df_long = df_long.rename(columns={'Asset class': 'asset_class'})
            
            # Standardize asset class names to required format (e.g., 'fx' -> 'FX')
            asset_name_map = {'fx': 'FX', 'rates': 'Rates', 'em macro': 'EM Macro'}
            df_long['asset_class'] = df_long['asset_class'].str.lower().map(asset_name_map)
            df_long.dropna(subset=['asset_class'], inplace=True) # Drop non-relevant asset classes
            
            df_long['Node'] = pd.to_numeric(df_long['Node'], errors='coerce')
            df_long['Value'] = pd.to_numeric(df_long['Value'], errors='coerce').fillna(0)
            
            all_processed_dfs[f"{metadata['var_type']}_{metadata['sheet_type']}"] = df_long

        return all_processed_dfs, True
    except Exception as e:
        st.error(f"Error loading or processing the Excel file: {e}")
        st.info("Please ensure the workbook contains the sheets: 'DVaR_COB', 'DVaR_Prev_COB', 'SVaR_COB', 'SVaR_Prev_COB' with the correct two-row header structure.")
        return None, False

@st.cache_data
def calculate_var_metrics(_processed_data):
    """
    Aggregates processed data to calculate VaR for each asset class based on its
    specific node, then calculates the total 'Macro' VaR.
    """
    agg_results = {}
    node_mapping = {'FX': 10, 'Rates': 22194, 'EM Macro': 137354}

    for key, df in _processed_data.items():
        asset_class_dfs = []
        
        for asset, node_id in node_mapping.items():
            filtered_df = df[(df['asset_class'] == asset) & (df['Node'] == node_id)]
            if not filtered_df.empty:
                aggregated = filtered_df.groupby(['Date', 'Pnl_Vector_Rank', 'Pnl_Vector_Name'])['Value'].sum().reset_index()
                aggregated = aggregated.rename(columns={'Value': f"{asset.replace(' ', '_')}_Value"})
                asset_class_dfs.append(aggregated)

        if not asset_class_dfs:
            agg_results[key] = pd.DataFrame() # Return empty if no data
            continue

        merged_df = reduce(lambda left, right: pd.merge(left, right, on=['Date', 'Pnl_Vector_Rank', 'Pnl_Vector_Name'], how='outer'), asset_class_dfs)
        merged_df = merged_df.fillna(0)
        
        value_cols = []
        for asset in node_mapping.keys():
            col_name = f"{asset.replace(' ', '_')}_Value"
            if col_name not in merged_df.columns:
                merged_df[col_name] = 0
            value_cols.append(col_name)

        merged_df['Macro_Value'] = merged_df[value_cols].sum(axis=1)
        agg_results[key] = merged_df
        
    return agg_results

@st.cache_data
def create_final_tables(_agg_results):
    """
    Merges current and previous day aggregated data to calculate the change in VaR.
    """
    # DVaR Final Table
    dvar_current = _agg_results.get('DVaR_current', pd.DataFrame())
    dvar_previous = _agg_results.get('DVaR_previous', pd.DataFrame())
    if dvar_current.empty: return pd.DataFrame(), pd.DataFrame()

    prev_cols = ['Date', 'Pnl_Vector_Rank'] + [col for col in dvar_previous.columns if '_Value' in col]
    dvar_previous_subset = dvar_previous[prev_cols] if not dvar_previous.empty else pd.DataFrame(columns=prev_cols)

    final_dvar = pd.merge(dvar_current, dvar_previous_subset, on=['Date', 'Pnl_Vector_Rank'], how='left', suffixes=('_Current', '_Previous'))
    final_dvar = final_dvar.fillna(0)

    for cat in ['Macro', 'FX', 'Rates', 'EM_Macro']:
        final_dvar[f'{cat}_Change'] = final_dvar.get(f'{cat}_Value_Current', 0) - final_dvar.get(f'{cat}_Value_Previous', 0)
    
    # SVaR Final Table
    svar_current = _agg_results.get('SVaR_current', pd.DataFrame())
    svar_previous = _agg_results.get('SVaR_previous', pd.DataFrame())
    final_svar = pd.DataFrame()
    if not svar_current.empty:
        svar_prev_subset = svar_previous[['Date', 'Pnl_Vector_Rank', 'Macro_Value']] if not svar_previous.empty else pd.DataFrame()
        final_svar = pd.merge(svar_current, svar_prev_subset, on=['Date', 'Pnl_Vector_Rank'], how='left', suffixes=('_Current', '_Previous'))
        final_svar['Macro_Change'] = final_svar.get('Macro_Value_Current', 0) - final_svar.get('Macro_Value_Previous', 0).fillna(0)

    return final_dvar, final_svar

# --- 3. Main Application UI ---
with st.sidebar:
    st.header("‚öôÔ∏è Controls")
    uploaded_file = st.file_uploader("Upload Your `Tail_analysis_auto.xlsx` Workbook", type=["xlsx"])
    debug_mode = st.checkbox("Enable Debug Mode", help="Display intermediate data frames for troubleshooting.")

st.title("üìâ Market Risk DVaR & SVaR Tail Analysis")
st.markdown("This application performs a comprehensive analysis of Diversified and Stressed Value at Risk tails. Upload your workbook to begin.")
st.divider()

if uploaded_file is None:
    st.info("Awaiting for the Excel workbook to be uploaded.")
else:
    processed_data, success = load_and_process_data(uploaded_file)
    
    if success:
        st.success("‚úÖ File loaded and processed successfully!")
        agg_results = calculate_var_metrics(processed_data)
        final_dvar_table, final_svar_table = create_final_tables(agg_results)

        if final_dvar_table.empty:
            st.warning("No DVaR data could be calculated based on the provided file and node mappings. Please check the file contents.")
        else:
            if debug_mode:
                st.subheader("üêû Debug Mode: Intermediate Data States")
                with st.expander("Show/Hide Raw Processed Data & Aggregations"):
                    for name, df in processed_data.items():
                        st.write(f"**DataFrame: `{name}`**"); st.dataframe(df.head())
                    for name, df in agg_results.items():
                        st.write(f"**Aggregated: `{name}`**"); st.dataframe(df.head())
            
            # --- 4. Top/Bottom Tails Analysis Table (AG-Grid) ---
            st.header("üìä Top & Bottom Macro DVaR Tails (Current COB)")
            gb = GridOptionsBuilder.from_dataframe(final_dvar_table)
            cell_style_jscode = JsCode("""
            function(params) {
                if (params.value < -0.001) { return {'color': '#c62828', 'backgroundColor': '#ffcdd2'}; }
                else if (params.value > 0.001) { return {'color': '#2e7d32', 'backgroundColor': '#c8e6c9'}; }
                return {'color': 'black', 'backgroundColor': 'white'};
            }""")

            gb.configure_column("Date", type=["dateColumn", "nonEditableColumn"], valueFormatter="new Date(value).toLocaleDateString('en-GB')", width=120)
            gb.configure_column("Pnl_Vector_Name", header_name="PNL Vector", width=160)

            for col_name in final_dvar_table.columns:
                if final_dvar_table[col_name].dtype in ['float64', 'int64']:
                    header = col_name.replace('_Value', '').replace('_', ' ')
                    gb.configure_column(col_name, header_name=header, type=["numericColumn"], 
                                        valueFormatter="params.value.toLocaleString('en-US', {minimumFractionDigits: 2, maximumFractionDigits: 2})", 
                                        width=140)
                    if 'Change' in col_name: gb.configure_column(col_name, cellStyle=cell_style_jscode)
            
            gridOptions = gb.build()
            
            display_cols = [c for c in ['Date', 'Pnl_Vector_Name', 'Macro_Value_Current', 'Macro_Value_Previous', 'Macro_Change',
                'FX_Value_Current', 'FX_Value_Previous', 'FX_Change', 'Rates_Value_Current', 'Rates_Value_Previous', 'Rates_Change',
                'EM_Macro_Value_Current', 'EM_Macro_Value_Previous', 'EM_Macro_Change'] if c in final_dvar_table.columns]

            st.subheader("Top 20 Positive Tails")
            AgGrid(final_dvar_table.nlargest(20, 'Macro_Value_Current')[display_cols], gridOptions=gridOptions, theme='streamlit', height=400, allow_unsafe_jscode=True, fit_columns_on_grid_load=True)
            st.subheader("Top 20 Negative Tails")
            AgGrid(final_dvar_table.nsmallest(20, 'Macro_Value_Current')[display_cols], gridOptions=gridOptions, theme='streamlit', height=400, allow_unsafe_jscode=True, fit_columns_on_grid_load=True)
            st.divider()

            # --- 5. Tabbed Interface ---
            tab_list = ["DVaR Trends", "Volatility", "Contribution", "Correlations", "Sensitivity Attribution", "SVaR Comparison"]
            tabs = st.tabs(tab_list)

            with tabs[0]: # DVaR Trends
                st.header("DVaR Evolution Over Time")
                melt_cols = [c for c in final_dvar_table.columns if 'Value_Current' in c or 'Value_Previous' in c]
                dvar_long = pd.melt(final_dvar_table, id_vars=['Date'], value_vars=melt_cols, var_name='Metric', value_name='DVaR_Value')
                dvar_long[['Asset_Class', 'Sheet_Type']] = dvar_long['Metric'].str.split('_Value_', expand=True)
                dvar_long['Date_str'] = dvar_long['Date'].dt.strftime('%d-%m-%Y')

                for asset in ['Macro', 'FX', 'Rates', 'EM_Macro']:
                    st.subheader(f"{asset.replace('_', ' ')} DVaR Trend")
                    chart_data = dvar_long[dvar_long['Asset_Class'] == asset]
                    if not chart_data.empty:
                        line_chart = alt.Chart(chart_data).mark_line(point=alt.OverlayMarkDef(size=20)).encode(
                            x=alt.X('Date:T', title='Date', axis=alt.Axis(format='%d-%b-%Y')),
                            y=alt.Y('DVaR_Value:Q', title=f"{asset.replace('_', ' ')} DVaR Value"),
                            color=alt.Color('Sheet_Type:N', title='COB Type', legend=alt.Legend(orient="top")),
                            tooltip=[alt.Tooltip('Date_str:N', title='Date'), alt.Tooltip('DVaR_Value:Q', title='Value', format=',.2f')]
                        ).interactive()
                        st.altair_chart(line_chart, use_container_width=True)

            with tabs[1]: # Volatility
                st.header("Rolling Standard Deviation of DVaR")
                window = st.slider('Select Rolling Window Size (days):', min_value=5, max_value=60, value=30, key="vol_slider")
                vol_df = final_dvar_table.set_index('Date').sort_index()
                for asset in ['Macro', 'FX', 'Rates', 'EM_Macro']:
                    vol_df[f'{asset}_Vol_Current'] = vol_df.get(f'{asset}_Value_Current', 0).rolling(window=f'{window}D').std()
                    vol_df[f'{asset}_Vol_Previous'] = vol_df.get(f'{asset}_Value_Previous', 0).rolling(window=f'{window}D').std()
                
                vol_long = pd.melt(vol_df.reset_index(), id_vars=['Date'], value_vars=[c for c in vol_df.columns if '_Vol_' in c], var_name='Metric', value_name='Volatility').dropna()
                if not vol_long.empty:
                    vol_long[['Asset_Class', 'Sheet_Type']] = vol_long['Metric'].str.split('_Vol_', expand=True)
                    vol_long['Asset_Class'] = vol_long['Asset_Class'].str.replace('_', ' ')
                    vol_chart = alt.Chart(vol_long).mark_line().encode(
                        x=alt.X('Date:T', axis=alt.Axis(format='%d-%b-%Y')),
                        y=alt.Y('Volatility:Q', title='Rolling Standard Deviation'),
                        color='Sheet_Type:N',
                        facet=alt.Facet('Asset_Class:N', title=None, columns=2),
                    ).interactive().properties(title=f'{window}-Day Rolling Volatility')
                    st.altair_chart(vol_chart, use_container_width=True)
            
            with tabs[2]: # Contribution
                st.header("Asset Class Contribution to Macro DVaR (Current COB)")
                contrib_cols = ['Date', 'FX_Value_Current', 'Rates_Value_Current', 'EM_Macro_Value_Current']
                if all(c in final_dvar_table.columns for c in contrib_cols):
                    contrib_long = pd.melt(final_dvar_table, id_vars=['Date'], value_vars=contrib_cols[1:], var_name='Asset_Class', value_name='Contribution_Value')
                    contrib_long['Asset_Class'] = contrib_long['Asset_Class'].str.replace('_Value_Current', '').str.replace('_', ' ')
                    area_chart = alt.Chart(contrib_long).mark_area().encode(
                        x=alt.X('Date:T', axis=alt.Axis(format='%d-%b-%Y')),
                        y=alt.Y('Contribution_Value:Q', stack='normalize', title='Percentage Contribution', axis=alt.Axis(format='%')),
                        color=alt.Color('Asset_Class:N', title='Asset Class'),
                    ).interactive()
                    st.altair_chart(area_chart, use_container_width=True)

            with tabs[3]: # Correlations
                st.header("Correlation Matrix of Asset Class DVaR (Current COB)")
                corr_cols = ['FX_Value_Current', 'Rates_Value_Current', 'EM_Macro_Value_Current']
                if all(c in final_dvar_table.columns for c in corr_cols):
                    corr_df = final_dvar_table[corr_cols].rename(columns=lambda c: c.replace('_Value_Current', '').replace('_', ' '))
                    st.dataframe(corr_df.corr().style.format("{:.2f}").background_gradient(cmap='coolwarm', vmin=-1, vmax=1))

            with tabs[4]: # Sensitivity Attribution
                st.header("DVaR Contribution by Sensitivity Type (Current COB)")
                node_mapping_sens = {'FX': 10, 'Rates': 22194, 'EM Macro': 137354}
                asset_options = [ac for ac in ['FX', 'Rates', 'EM Macro'] if ac in processed_data['DVaR_current']['asset_class'].unique()]
                
                if asset_options:
                    asset_choice = st.selectbox("Select Asset Class:", options=asset_options, key="sens_asset")
                    top_n = st.slider("Show Top N Sensitivities:", min_value=2, max_value=20, value=7, key="sens_top_n")
                    
                    node_id_for_asset = node_mapping_sens[asset_choice]
                    sensitivity_data = processed_data['DVaR_current'][(processed_data['DVaR_current']['asset_class'] == asset_choice) & (processed_data['DVaR_current']['Node'] == node_id_for_asset)].copy()
                    
                    if not sensitivity_data.empty:
                        top_sensitivities = sensitivity_data.groupby('sensitivity_type')['Value'].apply(lambda x: x.abs().sum()).nlargest(top_n).index
                        sensitivity_data['sensitivity_group'] = np.where(sensitivity_data['sensitivity_type'].isin(top_sensitivities), sensitivity_data['sensitivity_type'], 'Other')
                        
                        attribution_df = sensitivity_data.groupby(['Date', 'sensitivity_group'])['Value'].sum().reset_index()
                        sensitivity_chart = alt.Chart(attribution_df).mark_area().encode(
                            x=alt.X('Date:T', axis=alt.Axis(format='%d-%b-%Y')),
                            y=alt.Y('Value:Q', title='DVaR Value', stack='zero'),
                            color=alt.Color('sensitivity_group:N', title='Sensitivity Type'),
                        ).interactive()
                        st.altair_chart(sensitivity_chart, use_container_width=True)
                    else:
                        st.warning(f"No sensitivity data found for {asset_choice} with Node ID {node_id_for_asset}.")

            with tabs[5]: # SVaR Comparison
                st.header("SVaR vs. DVaR Comparison")
                if not final_svar_table.empty:
                    comp_type = st.radio("Select COB Data for Comparison:", ('Current Day COB', 'Previous Day COB'), horizontal=True, key="svar_comp")
                    col_suffix = '_Current' if comp_type == 'Current Day COB' else '_Previous'
                    
                    dvar_vals = final_dvar_table[['Date', 'Pnl_Vector_Rank', f'Macro_Value{col_suffix}']].rename(columns={f'Macro_Value{col_suffix}': 'DVaR'})
                    svar_vals = final_svar_table[['Date', 'Pnl_Vector_Rank', f'Macro_Value{col_suffix}']].rename(columns={f'Macro_Value{col_suffix}': 'SVaR'})

                    comparison_df = pd.merge(dvar_vals, svar_vals, on=['Date', 'Pnl_Vector_Rank'], how='inner')
                    if not comparison_df.empty:
                        comparison_long = pd.melt(comparison_df, id_vars=['Date'], value_vars=['DVaR', 'SVaR'], var_name='VaR_Type', value_name='Value')
                        comp_chart = alt.Chart(comparison_long).mark_line().encode(x='Date:T', y='Value:Q', color='VaR_Type:N').interactive()
                        st.altair_chart(comp_chart, use_container_width=True)
                        
                        st.subheader("SVaR / DVaR Ratio Statistics")
                        comparison_df['Ratio'] = (comparison_df['SVaR'] / comparison_df['DVaR']).replace([np.inf, -np.inf], np.nan)
                        st.dataframe(comparison_df['Ratio'].describe().to_frame().style.format("{:.2f}"))

