import streamlit as st
import pandas as pd
import altair as alt
import io
import numpy as np
from st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode, DataReturnMode, JsCode

# --- Configuration (UPDATED) ---
CURRENT_DAY_SHEET_NAME = "DVaR_COB"
PREVIOUS_DAY_SHEET_NAME = "DVaR_Prev_COB"
SVAR_COB_SHEET_NAME = "SVaR_COB"
SVAR_PREV_COB_SHEET_NAME = "SVaR_Prev_COB"

# UPDATED: Node values for DVaR calculations
FX_DVAR_NODE = 10
RATES_DVAR_NODE = 22194
EM_MACRO_DVAR_NODE = 137354

# Asset Class mapping for internal keys to display names (UPDATED)
ASSET_CLASS_MAP = {
    'fx': 'FX',
    'rates': 'Rates',
    'em macro': 'EM Macro'
}

PNL_VECTOR_START = 261
PNL_VECTOR_END = 520

# --- Streamlit Application Setup ---
st.set_page_config(layout="wide", page_title="Market Risk DVaR Tail Analysis")
st.title("üìä Comprehensive Market Risk DVaR Tail Analysis")

# --- Sidebar for Controls & Filters ---
st.sidebar.title("‚öôÔ∏è Controls & Filters")
uploaded_file = st.sidebar.file_uploader(
    "Upload Tail_analysis_auto.xlsx",
    type="xlsx",
    help="Upload your Excel workbook to perform detailed DVaR and SVaR tail analysis."
)
DEBUG_MODE = st.sidebar.checkbox("Show Debug Info", value=False)


# --- Helper Functions ---

@st.cache_data
def load_data(file_buffer, debug_mode):
    """Loads data from the specified sheets in the Excel workbook."""
    data_frames = {}
    date_mappings = {}
    sheets_to_load = [
        CURRENT_DAY_SHEET_NAME, PREVIOUS_DAY_SHEET_NAME,
        SVAR_COB_SHEET_NAME, SVAR_PREV_COB_SHEET_NAME
    ]
    for sheet_name in sheets_to_load:
        try:
            file_buffer.seek(0)
            header_df = pd.read_excel(file_buffer, sheet_name=sheet_name, header=None, nrows=2)
            dates_row, column_names_row = header_df.iloc[0], header_df.iloc[1]

            file_buffer.seek(0)
            df = pd.read_excel(file_buffer, sheet_name=sheet_name, header=None, skiprows=2)
            df.columns = column_names_row
            df = df.dropna(axis=1, how='all')

            if 'Node' in df.columns:
                df['Node'] = pd.to_numeric(df['Node'], errors='coerce').astype('Int64')

            pnl_date_map = {}
            for idx, col_name in enumerate(column_names_row):
                if pd.notna(col_name) and str(col_name).startswith('pnl_vector'):
                    date_val = dates_row.iloc[idx]
                    if isinstance(date_val, (int, float)):
                        pnl_date_map[str(col_name)] = pd.to_datetime(date_val, unit='D', origin='1899-12-30')
                    else:
                        pnl_date_map[str(col_name)] = pd.to_datetime(date_val, errors='coerce')

            data_frames[sheet_name] = df
            date_mappings[sheet_name] = pnl_date_map
        except Exception as e:
            st.error(f"Error loading sheet '{sheet_name}': {e}. Check sheet names and format.")
            return None, None
    return data_frames, date_mappings

@st.cache_data
def calculate_var_tails(_df, _pnl_date_map, sheet_type, var_type_filter):
    """Calculates VaR tails. Works on copies to prevent mutation issues with cache."""
    if _df is None: return pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame()
    df = _df.copy()
    pnl_date_map = _pnl_date_map.copy()

    id_vars = ['Var Type', 'Node', 'Asset class', 'currency', 'sensitivity_type', 'load_code']
    pnl_cols = [c for c in df.columns if str(c).startswith('pnl_vector')]

    valid_pnl_cols = []
    for col in pnl_cols:
        col_str = str(col)
        is_t2 = '[T-2]' in col_str
        if var_type_filter == "DVaR":
            if sheet_type == "current" and not is_t2:
                try:
                    num = int(col_str.replace('pnl_vector', ''))
                    if PNL_VECTOR_START <= num <= PNL_VECTOR_END: valid_pnl_cols.append(col)
                except ValueError: continue
            elif sheet_type == "previous" and is_t2: valid_pnl_cols.append(col)
        elif var_type_filter == "SVaR":
            if sheet_type == "current" and not is_t2: valid_pnl_cols.append(col)
            elif sheet_type == "previous" and is_t2: valid_pnl_cols.append(col)
    
    if not valid_pnl_cols: return pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame()

    df_melted = df.melt(id_vars=[v for v in id_vars if v in df.columns], value_vars=valid_pnl_cols, var_name='Pnl_Vector_Name', value_name='Value')
    df_melted['Pnl_Vector_Rank'] = df_melted['Pnl_Vector_Name'].str.extract(r'(\d+)').astype(float).astype('Int64')
    df_melted['Date'] = pd.to_datetime(df_melted['Pnl_Vector_Name'].map(pnl_date_map), errors='coerce')
    df_melted.dropna(subset=['Date'], inplace=True)
    df_var_type = df_melted[df_melted['Var Type'] == var_type_filter].copy()

    asset_dfs = {}
    node_map = {'fx': FX_DVAR_NODE, 'rates': RATES_DVAR_NODE, 'em macro': EM_MACRO_DVAR_NODE}
    for ac_key, node in node_map.items():
        asset_df = df_var_type[(df_var_type['Asset class'] == ac_key) & (df_var_type['Node'] == node)]
        if not asset_df.empty:
            # Generate the column name using the proper display name from the map
            display_name = ASSET_CLASS_MAP[ac_key].replace(' ', '_')
            asset_dfs[ac_key] = asset_df.groupby(['Date', 'Pnl_Vector_Name', 'Pnl_Vector_Rank'])['Value'].sum().reset_index(name=f'{display_name}_{var_type_filter}_Value')
            asset_dfs[ac_key]['Sheet_Type'] = sheet_type
        else:
            asset_dfs[ac_key] = pd.DataFrame()

    macro_df = pd.DataFrame()
    if all(not df.empty for df in asset_dfs.values()):
        # Start with a copy of one dataframe to avoid modifying it directly
        macro_df = asset_dfs['fx'].copy()
        
        # Merge other dataframes
        for ac_key in ['rates', 'em macro']:
            macro_df = pd.merge(macro_df, asset_dfs[ac_key], on=['Date', 'Pnl_Vector_Name', 'Pnl_Vector_Rank', 'Sheet_Type'], how='outer')

        # Generate the list of columns to sum for Macro VaR
        value_cols_to_sum = [f'{ASSET_CLASS_MAP[ac_key].replace(" ", "_")}_{var_type_filter}_Value' for ac_key in node_map]
        macro_df[f'Macro_{var_type_filter}_Value'] = macro_df[value_cols_to_sum].sum(axis=1)
        macro_df = macro_df.sort_values('Date').reset_index(drop=True)

    return asset_dfs.get('fx'), asset_dfs.get('rates'), asset_dfs.get('em macro'), macro_df, df_var_type


# --- Visualization Functions (with fixes) ---

def plot_dvar_trends(df, title, y_column, legend_title="Type"):
    if df.empty: return
    chart = alt.Chart(df).mark_line(point=True).encode(
        x=alt.X('Date:T', title='Date', axis=alt.Axis(format='%d-%m-%Y')),
        y=alt.Y(y_column, title='DVaR Value'),
        color=alt.Color('Sheet_Type:N', title=legend_title),
        tooltip=[alt.Tooltip('Date:T', format='%d-%m-%Y'), alt.Tooltip(y_column, format=',.2f'), 'Sheet_Type']
    ).properties(title=title).interactive()
    st.altair_chart(chart, use_container_width=True)

def plot_dvar_volatility(df, title, y_column, window_size):
    if df.empty: return
    df['Rolling_Std_DVaR'] = df.groupby('Sheet_Type')[y_column].transform(lambda x: x.rolling(window=window_size).std())
    chart = alt.Chart(df.dropna()).mark_line().encode(
        x=alt.X('Date:T', title='Date', axis=alt.Axis(format='%d-%m-%Y')),
        y=alt.Y('Rolling_Std_DVaR', title='Rolling Std Dev'),
        color='Sheet_Type:N',
        tooltip=[alt.Tooltip('Date:T', format='%d-%m-%Y'), alt.Tooltip('Rolling_Std_DVaR', format=',.2f')]
    ).properties(title=title).interactive()
    st.altair_chart(chart, use_container_width=True)

def plot_contribution(df, title):
    if df.empty: return
    value_vars = [c for c in df.columns if '_DVaR_Value' in c and 'Macro' not in c]
    df_long = df.melt(id_vars=['Date', 'Macro_DVaR_Value'], value_vars=value_vars, var_name='Asset_Class', value_name='Contribution_Value')
    # Use the proper display name
    df_long['Asset_Class'] = df_long['Asset_Class'].str.replace('_DVaR_Value', '').str.replace('_', ' ')
    chart = alt.Chart(df_long).mark_area().encode(
        x=alt.X('Date:T', title='Date', axis=alt.Axis(format='%d-%m-%Y')),
        y=alt.Y('Contribution_Value:Q', title='Contribution to DVaR', stack='zero'),
        color=alt.Color('Asset_Class:N', title='Asset Class'),
        tooltip=[alt.Tooltip('Date:T', format='%d-%m-%Y'), 'Asset_Class:N', alt.Tooltip('Contribution_Value:Q', format=',.2f')]
    ).properties(title=title).interactive()
    st.altair_chart(chart, use_container_width=True)

def display_correlations(df):
    if df.empty: return
    value_cols = [c for c in df.columns if '_DVaR_Value' in c and 'Macro' not in c]
    if not value_cols: return
    
    # Rename columns for display in the correlation matrix
    correlation_df = df[value_cols].copy()
    correlation_df.columns = [col.replace('_DVaR_Value', '').replace('_', ' ') for col in correlation_df.columns]
    
    st.dataframe(correlation_df.corr().style.background_gradient(cmap='viridis').format("{:.2f}"))

def plot_sensitivity_attribution(df_raw, selected_asset_class_key):
    node_map = {'fx': FX_DVAR_NODE, 'rates': RATES_DVAR_NODE, 'em macro': EM_MACRO_DVAR_NODE}
    node_val = node_map.get(selected_asset_class_key)
    display_name = ASSET_CLASS_MAP[selected_asset_class_key]
    
    df_asset = df_raw[(df_raw['Asset class'] == selected_asset_class_key) & (df_raw['Node'] == node_val)]
    if df_asset.empty:
        st.info(f"No data for '{display_name}' with Node {node_val}.")
        return
    
    sens_contrib = df_asset.groupby(['Date', 'sensitivity_type'])['Value'].sum().reset_index()
    top_n = st.slider(f"Top N Sensitivities for {display_name}", 5, 20, 10, key=f"sens_{selected_asset_class_key}")
    top_sensitivities = sens_contrib.groupby('sensitivity_type')['Value'].mean().abs().nlargest(top_n).index
    sens_contrib['Display_Sensitivity'] = sens_contrib['sensitivity_type'].where(sens_contrib['sensitivity_type'].isin(top_sensitivities), 'Other')
    df_display = sens_contrib.groupby(['Date', 'Display_Sensitivity'])['Value'].sum().reset_index()

    chart = alt.Chart(df_display).mark_area().encode(
        x=alt.X('Date:T', title='Date', axis=alt.Axis(format='%d-%m-%Y')),
        y=alt.Y('Value:Q', title='Contribution to DVaR', stack='zero'),
        color=alt.Color('Display_Sensitivity:N', title='Sensitivity Type'),
        tooltip=[alt.Tooltip('Date:T', format='%d-%m-%Y'), 'Display_Sensitivity:N', alt.Tooltip('Value:Q', format=',.2f')]
    ).properties(title=f"DVaR Contribution by Sensitivity for {display_name}").interactive()
    st.altair_chart(chart, use_container_width=True)

def plot_svar_dvar_comparison(dvar_df, svar_df, title):
    if dvar_df.empty or svar_df.empty:
        st.info(f"Data not available for {title}.")
        return
    
    merged_df = pd.merge(dvar_df[['Date', 'Macro_DVaR_Value']], svar_df[['Date', 'Macro_SVaR_Value']], on='Date', how='inner')
    df_melted = merged_df.melt(id_vars=['Date'], value_vars=['Macro_DVaR_Value', 'Macro_SVaR_Value'], var_name='VaR_Type', value_name='Value')

    chart = alt.Chart(df_melted).mark_line(point=True).encode(
        x=alt.X('Date:T', title='Date', axis=alt.Axis(format='%d-%m-%Y')),
        y=alt.Y('Value:Q', title='VaR Value'),
        color='VaR_Type:N',
        strokeDash='VaR_Type:N',
        tooltip=[alt.Tooltip('Date:T', format='%d-%m-%Y'), 'VaR_Type:N', alt.Tooltip('Value:Q', format=',.2f')]
    ).properties(title=title).interactive()
    st.altair_chart(chart, use_container_width=True)

# --- Main App Logic ---

if not uploaded_file:
    st.info("Please upload your Excel file using the sidebar to begin analysis.")
else:
    data_sheets, date_mappings = load_data(io.BytesIO(uploaded_file.getvalue()), DEBUG_MODE)
    if not data_sheets: st.stop()

    with st.spinner("Calculating VaR tails... This may take a moment."):
        fx_dvar_curr, rates_dvar_curr, em_macro_dvar_curr, macro_dvar_curr, raw_dvar_curr = calculate_var_tails(
            data_sheets.get(CURRENT_DAY_SHEET_NAME), date_mappings.get(CURRENT_DAY_SHEET_NAME), "current", "DVaR")
        fx_dvar_prev, rates_dvar_prev, em_macro_dvar_prev, macro_dvar_prev, _ = calculate_var_tails(
            data_sheets.get(PREVIOUS_DAY_SHEET_NAME), date_mappings.get(PREVIOUS_DAY_SHEET_NAME), "previous", "DVaR")
        _, _, _, macro_svar_curr, _ = calculate_var_tails(
            data_sheets.get(SVAR_COB_SHEET_NAME), date_mappings.get(SVAR_COB_SHEET_NAME), "current", "SVaR")
        _, _, _, macro_svar_prev, _ = calculate_var_tails(
            data_sheets.get(SVAR_PREV_COB_SHEET_NAME), date_mappings.get(SVAR_PREV_COB_SHEET_NAME), "previous", "SVaR")
    
    if macro_dvar_curr.empty or macro_dvar_prev.empty:
        st.error("Could not calculate DVaR. Check file format, sheet names, node values, and enable debug mode.")
        st.stop()
    
    st.success("Calculations complete! You can now explore the analysis tabs.")

    # --- KPI Dashboard ---
    st.subheader("Key Risk Metrics (Current COB Latest Day)")
    latest_dvar = macro_dvar_curr['Macro_DVaR_Value'].iloc[-1]
    latest_dvar_prev = macro_dvar_prev['Macro_DVaR_Value'].iloc[-1]
    latest_svar = macro_svar_curr['Macro_SVaR_Value'].iloc[-1] if not macro_svar_curr.empty else 0
    svar_dvar_ratio = latest_svar / latest_dvar if latest_dvar != 0 else 0
    col1, col2, col3 = st.columns(3)
    col1.metric("Latest Macro DVaR", f"${latest_dvar:,.2f}", f"${(latest_dvar - latest_dvar_prev):,.2f} vs Prev.")
    col2.metric("Latest Macro SVaR", f"${latest_svar:,.2f}")
    col3.metric("SVaR / DVaR Ratio", f"{svar_dvar_ratio:.2f}", help="Stress uplift factor")
    st.divider()

    # --- Global Date Filter ---
    st.sidebar.header("Global Date Filter")
    min_date = macro_dvar_curr['Date'].min().date()
    max_date = macro_dvar_curr['Date'].max().date()
    date_range = st.sidebar.date_input("Select a date range", (min_date, max_date), min_date, max_date)
    
    start_date, end_date = pd.to_datetime(date_range[0]), pd.to_datetime(date_range[1])
    def filter_by_date(df):
        return df[df['Date'].between(start_date, end_date)] if not df.empty else df

    macro_dvar_curr_f, macro_dvar_prev_f = filter_by_date(macro_dvar_curr), filter_by_date(macro_dvar_prev)
    fx_dvar_curr_f, fx_dvar_prev_f = filter_by_date(fx_dvar_curr), filter_by_date(fx_dvar_prev)
    rates_dvar_curr_f, rates_dvar_prev_f = filter_by_date(rates_dvar_curr), filter_by_date(rates_dvar_prev)
    em_macro_dvar_curr_f, em_macro_dvar_prev_f = filter_by_date(em_macro_dvar_curr), filter_by_date(em_macro_dvar_prev)
    macro_svar_curr_f, macro_svar_prev_f = filter_by_date(macro_svar_curr), filter_by_date(macro_svar_prev)
    raw_dvar_curr_f = filter_by_date(raw_dvar_curr)

    # --- Analysis Tabs ---
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
        "DVaR Trends", "Volatility", "Contribution", "Correlations",
        "Sensitivity Attribution", "SVaR Comparison"
    ])

    with tab1:
        st.header("üìà DVaR Time Series Trends")
        all_macro = pd.concat([macro_dvar_curr_f, macro_dvar_prev_f])
        plot_dvar_trends(all_macro, "Macro DVaR Trend (Current vs. Previous Day)", 'Macro_DVaR_Value')
        st.subheader("Individual Asset Class DVaR Trends")
        c1, c2, c3 = st.columns(3)
        with c1: plot_dvar_trends(pd.concat([fx_dvar_curr_f, fx_dvar_prev_f]), f"{ASSET_CLASS_MAP['fx']} DVaR", f"{ASSET_CLASS_MAP['fx']}_DVaR_Value")
        with c2: plot_dvar_trends(pd.concat([rates_dvar_curr_f, rates_dvar_prev_f]), f"{ASSET_CLASS_MAP['rates']} DVaR", f"{ASSET_CLASS_MAP['rates']}_DVaR_Value")
        with c3: plot_dvar_trends(pd.concat([em_macro_dvar_curr_f, em_macro_dvar_prev_f]), f"{ASSET_CLASS_MAP['em macro']} DVaR", f"{ASSET_CLASS_MAP['em macro'].replace(' ', '_')}_DVaR_Value")

    with tab2:
        st.header("üìâ DVaR Volatility Analysis")
        window = st.slider("Select Rolling Window (days)", 5, 60, 20)
        plot_dvar_volatility(pd.concat([macro_dvar_curr_f, macro_dvar_prev_f]), "Macro DVaR Rolling Volatility", 'Macro_DVaR_Value', window)

    with tab3:
        st.header("üèõÔ∏è Asset Class Contribution to Macro DVaR")
        plot_contribution(macro_dvar_curr_f, "Asset Class Contribution to Macro DVaR (Current Day)")

    with tab4:
        st.header("ü§ù Asset Class DVaR Correlations")
        display_correlations(macro_dvar_curr_f)

    with tab5:
        st.header("üî¨ DVaR Sensitivity Attribution")
        # Use the map to create display options, but pass the key to the function
        options_map = {ASSET_CLASS_MAP[k]: k for k in ASSET_CLASS_MAP if k in raw_dvar_curr_f['Asset class'].unique()}
        if options_map:
            selected_display_name = st.selectbox("Select Asset Class", list(options_map.keys()), key='sens_ac_select')
            selected_key = options_map[selected_display_name]
            plot_sensitivity_attribution(raw_dvar_curr_f, selected_key)

    with tab6:
        st.header("‚öñÔ∏è SVaR vs. DVaR Comparison")
        comp_type = st.radio("Select Data Type", ('Current Day COB', 'Previous Day COB'))
        dvar_df = macro_dvar_curr_f if comp_type == 'Current Day COB' else macro_dvar_prev_f
        svar_df = macro_svar_curr_f if comp_type == 'Current Day COB' else macro_svar_prev_f
        plot_svar_dvar_comparison(dvar_df, svar_df, f"Macro SVaR vs. DVaR ({comp_type})")
