#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
VaR Explain — Executive Summary Generator
Author: You + ChatGPT
"""

import argparse
import re
from pathlib import Path
from typing import Dict, List, Optional

import pandas as pd

# ----------------------------- CONFIG ---------------------------------

CONFIG = {
    # Columns that might contain the desk/name/path (in order of preference).
    "name_columns": [
        "Drilldowns",   # <-- added for your case
        "Desk",
        "Name",
        "Book",
        "Path",
        "Description",
        "desc"
    ],
    # Candidate header patterns for key metrics.
    "col_patterns": {
        "var95":       [r"^var\s*95$", r"^var95$", r"^mgt.*var\s*95$", r"^mgt.*total.*var\s*95$"],
        "var95_t2":    [r"^var\s*95.*t-2$", r"^var95\[t-2\]$"],
        "deltacovar95":[r"^delta.*95$", r"^deltacovar95$"],
        "var99":       [r"^var\s*99$", r"^var99$", r"^mgt.*var\s*99$"],
        "var99_t2":    [r"^var\s*99.*t-2$", r"^var99\[t-2\]$"],
        "deltacovar99":[r"^delta.*99$", r"^deltacovar99$"],
        "limit":       [r"^limit.*amount$", r"^limit$", r"^limitamount$"],
    },
    # Region heuristics
    "region_rules": [
        ("Americas", [r"americas?", r"us\b", r"ny\b", r"mexic", r"latam", r"br[az]il"]),
        ("APAC",     [r"apac", r"asia", r"india", r"singapore", r"hong\s*kong", r"shanghai", r"prc"]),
        ("EMEA",     [r"emea", r"london", r"poland", r"huf", r"rub", r"ce3", r"israel", r"hungar"]),
    ],
    "top_n": 10,
    "sheets": {
        "summary": "Executive Summary",
        "top95":   "Top Movers 95",
        "top99":   "Top Movers 99",
        "regions": "Regional Roll-up",
        "raw":     "Raw (trimmed)"
    }
}

# --------------------------- UTILITIES --------------------------------

def normalize_col(col: str) -> str:
    return str(col).strip()

def pick_first_matching_column(columns: List[str], patterns: List[str]) -> Optional[str]:
    low_cols = [c.lower() for c in columns]
    for pat in patterns:
        rx = re.compile(pat, flags=re.I)
        for i, lc in enumerate(low_cols):
            if rx.search(lc):
                return columns[i]
    return None

def find_metric_columns(df: pd.DataFrame) -> Dict[str, Optional[str]]:
    cols = [normalize_col(c) for c in df.columns]
    mapping = {}
    for key, pats in CONFIG["col_patterns"].items():
        mapping[key] = pick_first_matching_column(cols, pats)
    return mapping

def find_name_column(df: pd.DataFrame) -> Optional[str]:
    cols = [normalize_col(c) for c in df.columns]
    for candidate in CONFIG["name_columns"]:
        for c in cols:
            if candidate.lower() in c.lower():   # <-- substring match
                return c
    # fallback: first object column
    obj_cols = [c for c in df.columns if df[c].dtype == "object"]
    return obj_cols[0] if obj_cols else None

def strip_id_prefix(name: str) -> str:
    if not isinstance(name, str):
        return str(name)
    return re.sub(r"^\s*\d+\s*,\s*", "", name.strip())

def infer_region(name: str) -> str:
    s = name.lower() if isinstance(name, str) else ""
    for region, patterns in CONFIG["region_rules"]:
        for pat in patterns:
            if re.search(pat, s):
                return region
    return "Unmapped"

def safe_num(series: pd.Series) -> pd.Series:
    return pd.to_numeric(series, errors="coerce").fillna(0.0)

# --------------------------- CORE LOGIC --------------------------------

def compute_var_explain(df: pd.DataFrame) -> Dict[str, pd.DataFrame]:
    df = df.copy()
    df.columns = [normalize_col(c) for c in df.columns]

    name_col = find_name_column(df)
    if not name_col:
        raise ValueError("Could not locate a desk/name column (check CONFIG['name_columns']).")

    mcols = find_metric_columns(df)
    keep_cols = [name_col] + [c for c in mcols.values() if c is not None]
    trimmed = df[keep_cols].copy()
    trimmed.rename(columns={name_col: "DeskPath"}, inplace=True)
    trimmed["Desk"] = trimmed["DeskPath"].astype(str).map(strip_id_prefix)

    for k, c in mcols.items():
        if c is not None:
            trimmed[k.upper()] = safe_num(trimmed[c])
        else:
            trimmed[k.upper()] = 0.0

    trimmed["dVaR95"] = trimmed["VAR95"] - trimmed["VAR95_T2"]
    trimmed["dVaR99"] = trimmed["VAR99"] - trimmed["VAR99_T2"]
    trimmed["Region"] = trimmed["Desk"].map(infer_region)

    movers95 = trimmed.sort_values("dVaR95", key=abs, ascending=False)
    movers99 = trimmed.sort_values("dVaR99", key=abs, ascending=False)

    reg95 = trimmed.groupby("Region", as_index=False).agg(VAR95=("VAR95","sum"),
                                                          dVaR95=("dVaR95","sum"))
    reg99 = trimmed.groupby("Region", as_index=False).agg(VAR99=("VAR99","sum"),
                                                          dVaR99=("dVaR99","sum"))

    totals = pd.DataFrame([{
        "VaR95": trimmed["VAR95"].sum(),
        "VaR95_T2": trimmed["VAR95_T2"].sum(),
        "ΔVaR95": trimmed["dVaR95"].sum(),
        "VaR99": trimmed["VAR99"].sum(),
        "VaR99_T2": trimmed["VAR99_T2"].sum(),
        "ΔVaR99": trimmed["dVaR99"].sum(),
    }])

    text = f"""
EM Macro VaR Summary
- VaR95: {totals.loc[0,'VaR95']:,.0f} (Δ {totals.loc[0,'ΔVaR95']:,.0f})
- VaR99: {totals.loc[0,'VaR99']:,.0f} (Δ {totals.loc[0,'ΔVaR99']:,.0f})
"""
    summary_text = pd.DataFrame({"Executive_Summary":[text]})

    return {
        "totals": totals,
        "movers95": movers95[["Desk","Region","VAR95","dVaR95"]].head(CONFIG["top_n"]),
        "movers99": movers99[["Desk","Region","VAR99","dVaR99"]].head(CONFIG["top_n"]),
        "reg95": reg95,
        "reg99": reg99,
        "trimmed": trimmed,
        "summary_text": summary_text
    }

# --------------------------- MAIN --------------------------------

def main():
    parser = argparse.ArgumentParser(description="Generate Executive VaR Explain from Excel.")
    parser.add_argument("--file", required=True, help="Path to Excel file exported from the VaR drilldown.")
    parser.add_argument("--sheet", default=None, help="Sheet name (optional).")
    parser.add_argument("--out", default="VaR_Explain_Summary.xlsx", help="Output Excel filename.")
    args = parser.parse_args()

    xls = pd.ExcelFile(args.file)
    sheet = args.sheet or xls.sheet_names[0]
    df = pd.read_excel(xls, sheet_name=sheet, header=0)

    results = compute_var_explain(df)

    out_path = Path(args.out)
    with pd.ExcelWriter(out_path, engine="xlsxwriter") as writer:
        results["summary_text"].to_excel(writer, sheet_name=CONFIG["sheets"]["summary"], index=False)
        results["totals"].to_excel(writer, sheet_name=CONFIG["sheets"]["summary"], index=False, startrow=3)
        results["movers95"].to_excel(writer, sheet_name=CONFIG["sheets"]["top95"], index=False)
        results["movers99"].to_excel(writer, sheet_name=CONFIG["sheets"]["top99"], index=False)
        results["reg95"].to_excel(writer, sheet_name=CONFIG["sheets"]["regions"], index=False)
        results["reg99"].to_excel(writer, sheet_name=CONFIG["sheets"]["regions"], index=False, startrow=len(results["reg95"])+3)
        results["trimmed"].to_excel(writer, sheet_name=CONFIG["sheets"]["raw"], index=False)

    print(f"[OK] Wrote executive summary to: {out_path.resolve()}")

if __name__ == "__main__":
    main()
