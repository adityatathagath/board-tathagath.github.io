import os
import time
import logging
from concurrent.futures import ProcessPoolExecutor, as_completed

import xlwings as xw
import pandas as pd

# ─── 1) CONFIGURATION ────────────────────────────────────────────────────
# Path to your Ice_Report_Legacy add-in
XLL_PATH    = r"C:\Path\To\IceAddIn.xll"

# Directory where CSVs will be saved
OUTPUT_DIR  = r"C:\Data\IceReports"

# List of (report_id, lag, name) tuples for all your reports
REPORT_PARAMS = [
    (20489527, 1, "INR_DailyRates"),
    (20489527, 2, "INR_DailyRates_T2"),
    (20486527, 1, "BRL_CreditSpreads"),
    # … add your remaining entries here …
]

# Maximum number of parallel Excel processes
MAX_WORKERS = 4

# Log file for tracking progress
LOG_FILE    = "ice_report_fetch.log"


# ─── 2) LOGGER SETUP ─────────────────────────────────────────────────────
def setup_logging():
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s %(levelname)-8s %(message)s",
        handlers=[
            logging.FileHandler(LOG_FILE, mode="a"),
            logging.StreamHandler()
        ]
    )
    logging.info(f"Output directory: {OUTPUT_DIR}")


# ─── 3) WORKER FUNCTION ───────────────────────────────────────────────────
def fetch_report(params):
    report_id, lag, name = params
    out_csv = os.path.join(OUTPUT_DIR, f"{name}.csv")
    logging.info(f"[PID {os.getpid()}] Starting '{name}' (report_id={report_id}, lag={lag})")

    # Launch its own Excel COM process
    app = xw.App(visible=False, add_book=False)
    try:
        # Register XLL and run UDF entirely in memory
        app.api.RegisterXLL(XLL_PATH)
        safe_arr = app.api.Run("Ice_Report_Legacy", report_id, "", lag)

        # Convert SafeArray → list of lists
        data = [list(row) for row in safe_arr]
        headers, *rows = data

        # Build DataFrame and save CSV
        df = pd.DataFrame(rows, columns=headers)
        df.to_csv(out_csv, index=False)
        logging.info(f"[PID {os.getpid()}] Saved {len(df)} rows → {out_csv}")

    except Exception as e:
        logging.error(f"[PID {os.getpid()}] Error in '{name}': {e}")
    finally:
        app.kill()


# ─── 4) MAIN ENTRYPOINT ───────────────────────────────────────────────────
def main():
    setup_logging()

    with ProcessPoolExecutor(max_workers=MAX_WORKERS) as executor:
        # Submit all jobs
        futures = {executor.submit(fetch_report, params): params for params in REPORT_PARAMS}

        # As each finishes, raise/log exceptions
        for future in as_completed(futures):
            future.result()


if __name__ == "__main__":
    main()